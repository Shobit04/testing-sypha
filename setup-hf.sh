#!/bin/bash

# Setup script for Sypha C - Hugging Face Whisper + Ollama
# This script will install Ollama and help configure Hugging Face

echo "ğŸš€ Setting up Sypha C - Hugging Face Whisper + Ollama..."

# Check if Ollama is already installed
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
else
    echo "ğŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    
    # Add Ollama to PATH for current session
    export PATH=$PATH:$HOME/.local/bin
    
    echo "âœ… Ollama installed successfully"
fi

# Start Ollama service
echo "ğŸ”„ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to start
echo "â³ Waiting for Ollama to start..."
sleep 5

# Check if Ollama is running
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama service is running"
else
    echo "âŒ Failed to start Ollama service"
    exit 1
fi

# Download required model
echo "ğŸ“¥ Downloading Gemma 2B model..."
ollama pull gemma2b

# Verify model is installed
echo "ğŸ” Verifying model..."
ollama list

# Create .env file if it doesn't exist
if [ ! -f ".env" ]; then
    echo ""
    echo "ğŸ“ Creating .env file..."
    echo "HUGGING_FACE_ACCESS_TOKEN=your_access_token_here" > .env
    echo "WHISPER_MODEL=openai/whisper-medium" >> .env
    echo "GEMMA_MODEL=gemma2b" >> .env
    echo "âœ… .env file created"
    echo "âš ï¸  Please edit .env and add your Hugging Face access token"
else
    echo "âœ… .env file already exists"
fi

echo ""
echo "ğŸ‰ Setup complete! You can now run Sypha C:"
echo "   npm install"
echo "   npm start"
echo ""
echo "ğŸ’¡ Make sure to:"
echo "   1. Edit .env file with your Hugging Face access token"
echo "   2. Keep Ollama running: ollama serve"
echo "   3. Get your token from: https://huggingface.co/settings/tokens"
echo ""
echo "ğŸ’¡ You can stop Ollama with: pkill ollama"
